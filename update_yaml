#!/usr/bin/python

from lxml import etree
from pyquery import PyQuery as pq
import re
import sys

filename = 'mapr.yaml'
baseurl = 'http://maprdocs.mapr.com/home/ReferenceGuide/maprcli-REST-API-Syntax.html'

# Escape HTML text
# MapR doc bug: u'\u2013' should be '-'
def escape(text):
  return text.replace('<', '&lt;').replace('>', '&gt;').replace(u'\u2013', '-')

# Adjust spaces and line breaks
def normalize(d):
  pre_ancestors = d('pre *')
  for e in d('*'):
    if e in pre_ancestors:
      e.text = escape(e.text or '').replace('\n', '\n\n')
      e.tail = escape(e.tail or '').replace('\n', '\n\n')
    else:
      if e.tag == 'pre':
        e.text = escape(e.text or '').replace('\n', '\n\n')
      else:
        e.text = re.sub(r'\s+', ' ', escape(e.text or ''))
      e.tail = re.sub(r'\s+', ' ', escape(e.tail or ''))
  return d

# Replace HTML tags with Markdown
def replace_tags(d, selector, start, end, a_selector=None, a_start=None, a_end=None):
  elements = d(selector)
  for e in reversed(elements):
    start_tag, end_tag = start, end
    if a_selector:
      if replace_tags(pq(e), a_selector, a_start, a_end) and a_selector == 'a':
        start_tag, end_tag = '', ''
    html = escape(e.text or '')
    children = e.getchildren()
    if children:
      html += unicode('').join([etree.tostring(c) for c in children])
    href = e.get('href') or ''
    if href:
      href = '(' + href + ')'
    tail = escape(e.tail or '')
    pq(e).before(start_tag + html + end_tag + href + tail)
    parent = e.getparent()
    parent.remove(e)
  return elements

# Get the GFM representation of sub nodes
def gfm(elements):
  gfm = []
  for e in elements:
    d = pq(e)
    normalize(d)
    replace_tags(d, 'h2', '\n\n## ', '\n\n')
    replace_tags(d, 'strong','**', '**')
    replace_tags(d, 'code', '`', '`', 'a', '[`', '`]')
    replace_tags(d, 'a', '[', ']')
    replace_tags(d, 'ul ul', '', '', 'li', '\n  * ', '\n')
    replace_tags(d, 'ul', '\n', '\n', 'li', '\n* ', '\n')
    replace_tags(d, 'ol', '\n', '\n', 'li', '\n1. ', '\n')
    replace_tags(d, 'p,div', '\n\n\n', '\n\n\n')
    replace_tags(d, 'pre', '\n\n\n```\n\n', '\n\n```\n\n\n')
    replace_tags(d, 'span', '', '')
    d('*').remove_attr('class')
    gfm.append((d.html() or '').strip())
  return '\n\n\n'.join(gfm)

# Print headers
def print_headers(d):

  # Print info
  f.write('swagger: "2.0"\n')
  f.write('info:\n')
  f.write('  title: MapR API\n')
  f.write('  description: The information about the MapR REST API\n')

  # Print version
  version = d('meta[name=version]').attr.content
  f.write('  version: "' + version + '"\n')

  # Print other headers
  f.write('schemes:\n')
  f.write('  - https\n')
  f.write('basePath: /rest\n')
  f.write('produces:\n')
  f.write('  - application/json\n')
  f.write('securityDefinitions:\n')
  f.write('  BasicAuth:\n')
  f.write('    type: basic\n')
  f.write('security:\n')
  f.write('  - BasicAuth: []\n')
  f.write('paths:\n')

# Print command
def print_command(d, tag):

  # Get command path
  syntax = d('h2,p').filter('*:contains("Syntax") ~ *').text().replace('\n',' ')
  match = re.search('(?<=rest)/[a-z/<>]+', syntax)
  if not match:
    return
  path = match.group().replace('<','{').replace('>','}')

  # Handle MapR doc bug
  if re.search('acl-set', d.base_url):
    path = path.replace('edit', 'set')
  if re.search('stream_edit', d.base_url):
    path = path.replace('create', 'edit')
  if re.search('stream_upstream_remove', d.base_url):
    path = path.replace('add', 'remove')
  if re.search('volume-link-create', d.base_url):
    path = path.replace('remove', 'create')

  # Print progress
  sys.stderr.write('\r\033[KProcessing ' + path + '...')

  # Print summary and description
  current = d('.shortdesc') or d('p:first')
  summary = current.text().replace('\n',' ')
  elements = []
  if current.next('* p:contains("Syntax")'):
    current = current.next().children()
  else:
    current = current.next_all()
  for i in current.items():
    if i('h2,p').filter('*:contains("Syntax")'):
      break
    elements.append(i)
  description = gfm(elements)
  f.write('  ' + path + ':\n')
  f.write('    get:\n')
  f.write('      tags:\n')
  f.write('        - ' + tag + '\n')
  f.write('      summary: "' + summary + '"\n')
  f.write('      description: "' + description + '"\n')

  # Print parameters
  parameters = d('h2,p').filter('*:contains("Parameters") ~ * tbody')
  if parameters:
    f.write('      parameters:\n')
    for i in parameters.items('tr'):
      name = i('td:eq(0)').text().replace('\n',' ')

      # Handle MapR doc bug
      if name == 'virtualip end range':
        name = 'virtualipend'
      else:
        name = re.search(r'\w+', name).group()
      if name == 'json' or name == 'long':
        continue
      name = name[0].lower() + name[1:]

      description = gfm(i('td:eq(1)'))
      required = i('td:eq(0) strong')
      f.write('        - name: ' + name + '\n')
      if re.search('urls', d.base_url) and name == 'name':
        f.write('          in: path\n')
        required = True
      else:
        f.write('          in: query\n')
      if re.search('"', description):
        f.write('          description: \'' + description + '\'\n')
      else:
        f.write('          description: "' + description + '"\n')
      if required:
        f.write('          required: true\n')
      f.write('          type: string\n')

  # Print responses
  f.write('      responses:\n')
  f.write('        200:\n')
  f.write('          description: OK\n')

# Main
f = open(filename, "w")
d = pq(baseurl).make_links_absolute()
print_headers(d)
category_links = d('.link:gt(0) a')
for i in category_links.items():
  d = pq(i.attr.href).make_links_absolute()
  command_links = d('.link a')
  if command_links:
    for j in command_links.items():
      d = pq(j.attr.href).make_links_absolute()
      print_command(d, i.text())
  else:
    print_command(d, i.text())
f.close()

sys.stderr.write('\r\033[K')
sys.stderr.flush()
